{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98c1c494-af7a-41d1-830e-f39ca0ce8052",
   "metadata": {},
   "source": [
    "# Using a GitHub Personal Access Token (PAT) to Push/Pull from a SageMaker Notebook\n",
    "\n",
    "When working in SageMaker notebooks, you may often need to push code updates to GitHub repositories. However, SageMaker notebooks are typically launched with temporary instances that don’t persist configurations, including SSH keys, across sessions. This makes HTTPS-based authentication, secured with a GitHub Personal Access Token (PAT), a practical solution. PATs provide flexibility for authentication and enable seamless interaction with both public and private repositories directly from your notebook. \n",
    "\n",
    "> **Important Note**: Personal access tokens are powerful credentials that grant specific permissions to your GitHub account. To ensure security, only select the minimum necessary permissions and handle the token carefully.\n",
    "\n",
    "\n",
    "## Step 1: Generate a Personal Access Token (PAT) on GitHub\n",
    "\n",
    "1. Go to **Settings > Developer settings > Personal access tokens** on GitHub.\n",
    "2. Click **Generate new token**, select **Classic**.\n",
    "3. Give your token a descriptive name (e.g., \"SageMaker Access Token\") and set an expiration date if desired for added security.\n",
    "4. **Select the minimum permissions needed**:\n",
    "   - **For public repositories**: Choose only **`public_repo`**.\n",
    "   - **For private repositories**: Choose **`repo`** (full control of private repositories).\n",
    "   - Optional permissions, if needed:\n",
    "     - **`repo:status`**: Access commit status (if checking status checks).\n",
    "     - **`workflow`**: Update GitHub Actions workflows (only if working with GitHub Actions).\n",
    "5. Generate the token and **copy it** (you won’t be able to see it again).\n",
    "\n",
    "> **Caution**: Treat your PAT like a password. Avoid sharing it or exposing it in your code. Store it securely (e.g., via a password manager like LastPass) and consider rotating it regularly.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8519df3b-a610-45bd-bc97-89d202f08f0f",
   "metadata": {},
   "source": [
    "## Step 2: Configure Git `user.name` and `user.email`\n",
    "In your SageMaker or Jupyter notebook environment, run the following commands to set up your Git user information\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "170bc5ec-70b2-4266-824d-0835828fcdd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "!git config --global user.name \"Chris Endemann\"\n",
    "!git config --global user.email endeman@wisc.edu\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "355b1e89-6625-403b-a746-e88fc3e4c703",
   "metadata": {},
   "source": [
    "### Explanation\n",
    "\n",
    "- **`user.name`**: This is your GitHub username, which will appear in the commit history as the author of the changes.\n",
    "- **`user.email`**: This should match the email associated with your GitHub account so that commits are properly linked to your profile.\n",
    "\n",
    "Setting this globally (`--global`) will ensure the configuration persists across all repositories in the environment. If you’re working in a temporary environment, you may need to re-run this configuration after a restart."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "027f1b11-e43b-45ab-8315-a429805452f0",
   "metadata": {},
   "source": [
    "## Step 3: Use `getpass` to Prompt for Username and PAT\n",
    "\n",
    "The `getpass` library allows you to input your GitHub username and PAT without exposing them in the notebook. This approach ensures you’re not hardcoding sensitive information.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b41eaac5-69eb-4e88-8bda-1ba7e25a0beb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import getpass\n",
    "\n",
    "# Prompt for GitHub username and PAT securely\n",
    "# github_url = 'github.com/UW-Madison-DataScience/test_AWS.git' # found under Code -> Clone -> HTTPS (remote the https:// before the rest of the address)\n",
    "# username = input(\"GitHub Username: \")\n",
    "# token = getpass.getpass(\"GitHub Personal Access Token (PAT): \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b1856be-09fe-4010-94d0-02666b2b6a28",
   "metadata": {},
   "source": [
    "**Note**: After running, you may want to comment out the above code so that you don't have to enter in your login every time you run your whole notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "795dac33-3a26-40cd-b517-59b8600f68f8",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "### Explanation\n",
    "\n",
    "- **`input(\"GitHub Username: \")`**: Prompts you to enter your GitHub username.\n",
    "- **`getpass.getpass(\"GitHub Personal Access Token (PAT): \")`**: Prompts you to securely enter the PAT, keeping it hidden on the screen.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe5fe80-bc91-46ff-827e-257736d3f46c",
   "metadata": {},
   "source": [
    "\n",
    "## Step 4: Add, Commit, and Push Changes with Manual Authentication\n",
    "### 1. Navigate to the Repository Directory (adjust the path if needed):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "633b7da6-05aa-4c0d-b9ad-1677100fb994",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker/test_AWS\n"
     ]
    }
   ],
   "source": [
    "!pwd\n",
    "# !cd test_AWS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "547f37fc-2df2-4ddf-b910-abd4b744c01a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 2. Preview changes: You may see elaborate changes if you are tracking ipynb files directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "00dda9ff-513c-451c-8881-46e0aee4eeb1",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nbdiff /tmp/git-blob-FXsIz3/04_Interacting-with-code-repo.ipynb 04_Interacting-with-code-repo.ipynb\n",
      "--- /tmp/git-blob-FXsIz3/04_Interacting-with-code-repo.ipynb  2024-11-01 21:09:55.546916\n",
      "+++ 04_Interacting-with-code-repo.ipynb  2024-11-01 21:09:44.878867\n",
      "\u001b[34m\u001b[1m## modified /cells/0/source:\u001b[0m\n",
      "\u001b[36m@@ -1,11 +1,11 @@\u001b[m\n",
      "\u001b[31m-### Using a GitHub Personal Access Token (PAT) to Push from a SageMaker Notebook\u001b[m\n",
      "\u001b[32m+\u001b[m\u001b[32m# Using a GitHub Personal Access Token (PAT) to Push/Pull from a SageMaker Notebook\u001b[m\n",
      " \u001b[m\n",
      " When working in SageMaker notebooks, you may often need to push code updates to GitHub repositories. However, SageMaker notebooks are typically launched with temporary instances that don’t persist configurations, including SSH keys, across sessions. This makes HTTPS-based authentication, secured with a GitHub Personal Access Token (PAT), a practical solution. PATs provide flexibility for authentication and enable seamless interaction with both public and private repositories directly from your notebook. \u001b[m\n",
      " \u001b[m\n",
      " > **Important Note**: Personal access tokens are powerful credentials that grant specific permissions to your GitHub account. To ensure security, only select the minimum necessary permissions and handle the token carefully.\u001b[m\n",
      " \u001b[m\n",
      " \u001b[m\n",
      "\u001b[31m-### Step 1: Generate a Personal Access Token (PAT) on GitHub\u001b[m\n",
      "\u001b[32m+\u001b[m\u001b[32m## Step 1: Generate a Personal Access Token (PAT) on GitHub\u001b[m\n",
      " \u001b[m\n",
      " 1. Go to **Settings > Developer settings > Personal access tokens** on GitHub.\u001b[m\n",
      " 2. Click **Generate new token**, select **Classic**.\u001b[m\n",
      "\n",
      "\u001b[0m\u001b[34m\u001b[1m## modified /cells/1/source:\u001b[0m\n",
      "\u001b[36m@@ -1,2 +1,2 @@\u001b[m\n",
      "\u001b[31m-### Step 2: Configure Git `user.name` and `user.email`\u001b[m\n",
      "\u001b[32m+\u001b[m\u001b[32m## Step 2: Configure Git `user.name` and `user.email`\u001b[m\n",
      " In your SageMaker or Jupyter notebook environment, run the following commands to set up your Git user information\u001b[m\n",
      "\n",
      "\u001b[0m\u001b[34m\u001b[1m## replaced /cells/2/execution_count:\u001b[0m\n",
      "\u001b[31m-  44\n",
      "\u001b[32m+  71\n",
      "\n",
      "\u001b[0m\u001b[34m\u001b[1m## modified /cells/4/source:\u001b[0m\n",
      "\u001b[36m@@ -1,3 +1,3 @@\u001b[m\n",
      "\u001b[31m-### Step 3: Use `getpass` to Prompt for Username and PAT\u001b[m\n",
      "\u001b[32m+\u001b[m\u001b[32m## Step 3: Use `getpass` to Prompt for Username and PAT\u001b[m\n",
      " \u001b[m\n",
      " The `getpass` library allows you to input your GitHub username and PAT without exposing them in the notebook. This approach ensures you’re not hardcoding sensitive information.\u001b[m\n",
      "\n",
      "\u001b[0m\u001b[34m\u001b[1m## replaced /cells/5/execution_count:\u001b[0m\n",
      "\u001b[31m-  45\n",
      "\u001b[32m+  72\n",
      "\n",
      "\u001b[0m\u001b[34m\u001b[1m## modified /cells/8/source:\u001b[0m\n",
      "\u001b[36m@@ -1,3 +1,3 @@\u001b[m\n",
      " \u001b[m\n",
      "\u001b[31m-### Step 4: Add, Commit, and Push Changes with Manual Authentication\u001b[m\n",
      "\u001b[31m-1. **Navigate to the Repository Directory** (adjust the path if needed):\u001b[m\n",
      "\u001b[32m+\u001b[m\u001b[32m## Step 4: Add, Commit, and Push Changes with Manual Authentication\u001b[m\n",
      "\u001b[32m+\u001b[m\u001b[32m### 1. Navigate to the Repository Directory (adjust the path if needed):\u001b[m\n",
      "\n",
      "\u001b[0m\u001b[34m\u001b[1m## replaced /cells/9/execution_count:\u001b[0m\n",
      "\u001b[31m-  32\n",
      "\u001b[32m+  73\n",
      "\n",
      "\u001b[0m\u001b[34m\u001b[1m## inserted before /cells/10:\u001b[0m\n",
      "\u001b[32m+  markdown cell:\n",
      "\u001b[32m+    id: 547f37fc-2df2-4ddf-b910-abd4b744c01a\n",
      "\u001b[32m+    metadata (known keys):\n",
      "\u001b[32m+      tags:\n",
      "\u001b[32m+        []\n",
      "\u001b[32m+    source:\n",
      "\u001b[32m+      2. **Preview changes**: You may see elaborate changes if you are tracking ipynb files directly.\n",
      "\u001b[32m+  code cell:\n",
      "\u001b[32m+    id: 00dda9ff-513c-451c-8881-46e0aee4eeb1\n",
      "\u001b[32m+    execution_count: 60\n",
      "\u001b[32m+    metadata (known keys):\n",
      "\u001b[32m+      tags:\n",
      "\u001b[32m+        []\n",
      "\u001b[32m+    metadata (unknown keys):\n",
      "\u001b[32m+      scrolled: True\n",
      "\u001b[32m+    source:\n",
      "\u001b[32m+      !git diff \n",
      "\u001b[32m+    outputs:\n",
      "\u001b[32m+      output 0:\n",
      "\u001b[32m+        output_type: stream\n",
      "\u001b[32m+        name: stdout\n",
      "\u001b[32m+        text:\n",
      "\u001b[32m+          nbdiff /tmp/git-blob-uCGzKR/04_Interacting-with-code-repo.ipynb 04_Interacting-with-code-repo.ipynb\n",
      "\u001b[32m+          --- /tmp/git-blob-uCGzKR/04_Interacting-with-code-repo.ipynb  2024-11-01 20:46:43.604458\n",
      "\u001b[32m+          +++ 04_Interacting-with-code-repo.ipynb  2024-11-01 20:45:42.160172\n",
      "\u001b[32m+          \u001b[34m\u001b[1m## replaced /cells/11/execution_count:\u001b[0m\n",
      "\u001b[32m+          \u001b[31m-  53\n",
      "\u001b[32m+          \u001b[32m+  55\n",
      "\u001b[32m+          \n",
      "\u001b[32m+          \u001b[0m\u001b[34m\u001b[1m## inserted before /cells/11/outputs/0:\u001b[0m\n",
      "\u001b[32m+          \u001b[32m+  output:\n",
      "\u001b[32m+          \u001b[32m+    output_type: stream\n",
      "\u001b[32m+          \u001b[32m+    name: stdout\n",
      "\u001b[32m+          \u001b[32m+    text:\n",
      "\u001b[32m+          \u001b[32m+      [main 0363cc2] Added updates from Jupyter notebook\n",
      "\u001b[32m+          \u001b[32m+       7 files changed, 416 insertions(+), 91 deletions(-)\n",
      "\u001b[32m+          \u001b[32m+       delete mode 100644 00_Data-storage-and-access-via-buckets.ipynb\n",
      "\u001b[32m+          \u001b[32m+       create mode 100644 01_Setting-up-S3-bucket.md\n",
      "\u001b[32m+          \u001b[32m+       create mode 100644 02_Setting-up-notebook-environment.md\n",
      "\u001b[32m+          \u001b[32m+       create mode 100644 03_Data-storage-and-access-via-buckets.ipynb\n",
      "\u001b[32m+          \u001b[32m+       rename push-git-updates.ipynb => 04_Interacting-with-code-repo.ipynb (77%)\n",
      "\u001b[32m+          \u001b[32m+       rename 01_Intro-train-models.ipynb => 05_Intro-train-models.ipynb (100%)\n",
      "\u001b[32m+          \u001b[32m+       rename 02_Hyperparameter-tuning.ipynb => 06_Hyperparameter-tuning.ipynb (100%)\n",
      "\u001b[32m+          \n",
      "\u001b[32m+          \u001b[0m\u001b[34m\u001b[1m## deleted /cells/11/outputs/0:\u001b[0m\n",
      "\u001b[32m+          \u001b[31m-  output:\n",
      "\u001b[32m+          \u001b[31m-    output_type: stream\n",
      "\u001b[32m+          \u001b[31m-    name: stdout\n",
      "\u001b[32m+          \u001b[31m-    text:\n",
      "\u001b[32m+          \u001b[31m-      [main 637d64c] Added updates from Jupyter notebook\n",
      "\u001b[32m+          \u001b[31m-       1 file changed, 19 insertions(+), 27 deletions(-)\n",
      "\u001b[32m+          \n",
      "\u001b[32m+          \u001b[0m\u001b[34m\u001b[1m## modified /cells/11/source:\u001b[0m\n",
      "\u001b[32m+          \u001b[36m@@ -1,2 +1,2 @@\u001b[m\n",
      "\u001b[32m+           !git add .\u001b[m\n",
      "\u001b[32m+          \u001b[31m-!git commit -m \"Added updates from Jupyter notebook\"\u001b[m\n",
      "\u001b[32m+          \u001b[32m+\u001b[m\u001b[32m!git commit -m \"Updates from Jupyter notebooks\" # in general, your commit message should be more specific!\u001b[m\n",
      "\u001b[32m+          \n",
      "\u001b[32m+          \u001b[0m\u001b[34m\u001b[1m## replaced /cells/13/execution_count:\u001b[0m\n",
      "\u001b[32m+          \u001b[31m-  51\n",
      "\u001b[32m+          \u001b[32m+  56\n",
      "\u001b[32m+          \n",
      "\u001b[32m+          \u001b[0m\u001b[34m\u001b[1m## inserted before /cells/13/outputs/0:\u001b[0m\n",
      "\u001b[32m+          \u001b[32m+  output:\n",
      "\u001b[32m+          \u001b[32m+    output_type: stream\n",
      "\u001b[32m+          \u001b[32m+    name: stdout\n",
      "\u001b[32m+          \u001b[32m+    text:\n",
      "\u001b[32m+          \u001b[32m+      From https://github.com/UW-Madison-DataScience/test_AWS\n",
      "\u001b[32m+          \u001b[32m+       * branch            main       -> FETCH_HEAD\n",
      "\u001b[32m+          \u001b[32m+         adfe7b1..637d64c  main       -> origin/main\n",
      "\u001b[32m+          \u001b[32m+      Already up to date.\n",
      "\u001b[32m+          \n",
      "\u001b[32m+          \u001b[0m\u001b[34m\u001b[1m## deleted /cells/13/outputs/0:\u001b[0m\n",
      "\u001b[32m+          \u001b[31m-  output:\n",
      "\u001b[32m+          \u001b[31m-    output_type: stream\n",
      "\u001b[32m+          \u001b[31m-    name: stdout\n",
      "\u001b[32m+          \u001b[31m-    text:\n",
      "\u001b[32m+          \u001b[31m-      remote: Enumerating objects: 7, done.\u001b[K\n",
      "\u001b[32m+          \u001b[31m-      remote: Counting objects: 100% (7/7), done.\u001b[K\n",
      "\u001b[32m+          \u001b[31m-      remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
      "\u001b[32m+          \u001b[31m-      remote: Total 6 (delta 2), reused 3 (delta 1), pack-reused 0 (from 0)\u001b[K\n",
      "\u001b[32m+          \u001b[31m-      Unpacking objects: 100% (6/6), 1.18 KiB | 1.18 MiB/s, done.\n",
      "\u001b[32m+          \u001b[31m-      From https://github.com/UW-Madison-DataScience/test_AWS\n",
      "\u001b[32m+          \u001b[31m-       * branch            main       -> FETCH_HEAD\n",
      "\u001b[32m+          \u001b[31m-         ebe991c..adfe7b1  main       -> origin/main\n",
      "\u001b[32m+          \u001b[31m-      Updating 2ff6cf0..adfe7b1\n",
      "\u001b[32m+          \u001b[31m-      Fast-forward\n",
      "\u001b[32m+          \u001b[31m-       .gitignore                                         |    3 \u001b[32m+\u001b[m\n",
      "\u001b[32m+          \u001b[31m-       ...storage-and-access-via-buckets-checkpoint.ipynb |    6 \u001b[31m-\u001b[m\n",
      "\u001b[32m+          \u001b[31m-       .../01_Intro-train-models-checkpoint.ipynb         | 2555 \u001b[31m--------------------\u001b[m\n",
      "\u001b[32m+          \u001b[31m-       .../02_Hyperparameter-tuning-checkpoint.ipynb      |  470 \u001b[31m----\u001b[m\n",
      "\u001b[32m+          \u001b[31m-       .../create_large_data-checkpoint.ipynb             |   54 \u001b[31m-\u001b[m\n",
      "\u001b[32m+          \u001b[31m-       .../push-git-updates-checkpoint.ipynb              |  322 \u001b[31m---\u001b[m\n",
      "\u001b[32m+          \u001b[31m-       .ipynb_checkpoints/train_nn-checkpoint.py          |   93 \u001b[31m-\u001b[m\n",
      "\u001b[32m+          \u001b[31m-       .ipynb_checkpoints/train_xgboost-checkpoint.py     |   65 \u001b[31m-\u001b[m\n",
      "\u001b[32m+          \u001b[31m-       __pycache__/train_xgboost.cpython-310.pyc          |  Bin \u001b[31m2194\u001b[m -> \u001b[32m0\u001b[m bytes\n",
      "\u001b[32m+          \u001b[31m-       9 files changed, 3 insertions(+), 3565 deletions(-)\n",
      "\u001b[32m+          \u001b[31m-       create mode 100644 .gitignore\n",
      "\u001b[32m+          \u001b[31m-       delete mode 100644 .ipynb_checkpoints/00_Data-storage-and-access-via-buckets-checkpoint.ipynb\n",
      "\u001b[32m+          \u001b[31m-       delete mode 100644 .ipynb_checkpoints/01_Intro-train-models-checkpoint.ipynb\n",
      "\u001b[32m+          \u001b[31m-       delete mode 100644 .ipynb_checkpoints/02_Hyperparameter-tuning-checkpoint.ipynb\n",
      "\u001b[32m+          \u001b[31m-       delete mode 100644 .ipynb_checkpoints/create_large_data-checkpoint.ipynb\n",
      "\u001b[32m+          \u001b[31m-       delete mode 100644 .ipynb_checkpoints/push-git-updates-checkpoint.ipynb\n",
      "\u001b[32m+          \u001b[31m-       delete mode 100644 .ipynb_checkpoints/train_nn-checkpoint.py\n",
      "\u001b[32m+          \u001b[31m-       delete mode 100644 .ipynb_checkpoints/train_xgboost-checkpoint.py\n",
      "\u001b[32m+          \u001b[31m-       delete mode 100644 __pycache__/train_xgboost.cpython-310.pyc\n",
      "\u001b[32m+          \n",
      "\u001b[32m+          \u001b[0m\u001b[34m\u001b[1m## replaced /cells/17/execution_count:\u001b[0m\n",
      "\u001b[32m+          \u001b[31m-  54\n",
      "\u001b[32m+          \u001b[32m+  57\n",
      "\u001b[32m+          \n",
      "\u001b[32m+          \u001b[0m\u001b[34m\u001b[1m## modified /cells/17/outputs/0/text:\u001b[0m\n",
      "\u001b[32m+          \u001b[36m@@ -1,9 +1,9 @@\u001b[m\n",
      "\u001b[32m+          \u001b[31m-Enumerating objects: 5, done.\u001b[m\n",
      "\u001b[32m+          \u001b[31m-Counting objects: 100% (5/5), done.\u001b[m\n",
      "\u001b[32m+          \u001b[32m+\u001b[m\u001b[32mEnumerating objects: 7, done.\u001b[m\n",
      "\u001b[32m+          \u001b[32m+\u001b[m\u001b[32mCounting objects: 100% (7/7), done.\u001b[m\n",
      "\u001b[32m+           Delta compression using up to 2 threads\u001b[m\n",
      "\u001b[32m+          \u001b[31m-Compressing objects: 100% (3/3), done.\u001b[m\n",
      "\u001b[32m+          \u001b[31m-Writing objects: 100% (3/3), 780 bytes | 780.00 KiB/s, done.\u001b[m\n",
      "\u001b[32m+          \u001b[31m-Total 3 (delta 2), reused 0 (delta 0), pack-reused 0\u001b[m\n",
      "\u001b[32m+          \u001b[31m-remote: Resolving deltas: 100% (2/2), completed with 2 local objects.\u001b[K\u001b[m\n",
      "\u001b[32m+          \u001b[32m+\u001b[m\u001b[32mCompressing objects: 100% (6/6), done.\u001b[m\n",
      "\u001b[32m+          \u001b[32m+\u001b[m\u001b[32mWriting objects: 100% (6/6), 11.22 KiB | 5.61 MiB/s, done.\u001b[m\n",
      "\u001b[32m+          \u001b[32m+\u001b[m\u001b[32mTotal 6 (delta 1), reused 0 (delta 0), pack-reused 0\u001b[m\n",
      "\u001b[32m+          \u001b[32m+\u001b[m\u001b[32mremote: Resolving deltas: 100% (1/1), completed with 1 local object.\u001b[K\u001b[m\n",
      "\u001b[32m+           To https://github.com/UW-Madison-DataScience/test_AWS.git\u001b[m\n",
      "\u001b[32m+          \u001b[31m-   adfe7b1..637d64c  main -> main\u001b[m\n",
      "\u001b[32m+          \u001b[32m+\u001b[m\u001b[32m   637d64c..0363cc2  main -> main\u001b[m\n",
      "\u001b[32m+          \n",
      "\u001b[32m+          \u001b[0m\u001b[34m\u001b[1m## deleted /cells/18:\u001b[0m\n",
      "\u001b[32m+          \u001b[31m-  code cell:\n",
      "\u001b[32m+          \u001b[31m-    id: 34b627ea-b2e4-439f-91e9-4dc2b0244aeb\n",
      "\u001b[32m+          \n",
      "\u001b[32m+          \u001b[0m\n",
      "\u001b[32m+  markdown cell:\n",
      "\u001b[32m+    id: c65f534e-4947-4078-80ab-6f21af394826\n",
      "\u001b[32m+    source:\n",
      "\u001b[32m+      3. **Convert json ipynb files to .py**\n",
      "\u001b[32m+      \n",
      "\u001b[32m+      To avoid tracking ipynb files directly, which are formatted as json, we may want to convert our notebook to .py first (plain text). This will make it easier to see our code edits across commits. Otherwise, each small edit will have massive changes associated with it.\n",
      "\u001b[32m+  markdown cell:\n",
      "\u001b[32m+    id: 8f8d3816-0f3d-4731-bb9f-ff3b4b9375c7\n",
      "\u001b[32m+    source:\n",
      "\u001b[32m+      Converting Jupyter Notebook code (`.ipynb`) to Python scripts (`.py`) before committing is a good practice, especially if you're working on collaborative projects where `.py` files are easier to version control and execute. Fortunately, Jupyter Notebooks (including SageMaker notebooks) provide an easy way to convert notebook code to `.py` format directly from within the notebook environment.\n",
      "\u001b[32m+      \n",
      "\u001b[32m+      Here’s how to convert `.ipynb` files to `.py` in SageMaker without needing to export or download files:\n",
      "\u001b[32m+      \n",
      "\u001b[32m+      ### Method 1: Using JupyText\n",
      "\u001b[32m+      \n",
      "\u001b[32m+      1. **Install Jupytext** (if you haven’t already):\n",
      "\u001b[32m+  markdown cell:\n",
      "\u001b[32m+    id: 93c388f4-3a99-4519-9033-9c6df9b44a06\n",
      "\u001b[32m+    source:\n",
      "\u001b[32m+      \n",
      "\u001b[32m+      ### Benefits of converting to `.py` before Committing\n",
      "\u001b[32m+      \n",
      "\u001b[32m+      - **Cleaner Version Control**: `.py` files have cleaner diffs and are easier to review and merge in Git.\n",
      "\u001b[32m+      - **Script Compatibility**: Python files are more compatible with other environments and can run easily from the command line.\n",
      "\u001b[32m+      - **Reduced Repository Size**: `.py` files are generally lighter than `.ipynb` files since they don’t store outputs or metadata.\n",
      "\u001b[32m+      \n",
      "\u001b[32m+      Converting notebooks to `.py` files helps streamline the workflow for both collaborative projects and deployments. This approach also maintains code readability and minimizes potential issues with notebook-specific metadata in Git history.\n",
      "\u001b[32m+  code cell:\n",
      "\u001b[32m+    id: 2cb6345d-16b7-44af-b026-98abe4a060a7\n",
      "\u001b[32m+    execution_count: 68\n",
      "\u001b[32m+    metadata (known keys):\n",
      "\u001b[32m+      tags:\n",
      "\u001b[32m+        []\n",
      "\u001b[32m+    source:\n",
      "\u001b[32m+      !pip install jupytext\n",
      "\u001b[32m+    outputs:\n",
      "\u001b[32m+      output 0:\n",
      "\u001b[32m+        output_type: stream\n",
      "\u001b[32m+        name: stdout\n",
      "\u001b[32m+        text:\n",
      "\u001b[32m+          Requirement already satisfied: jupytext in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (1.16.4)\n",
      "\u001b[32m+          Requirement already satisfied: markdown-it-py>=1.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from jupytext) (3.0.0)\n",
      "\u001b[32m+          Requirement already satisfied: mdit-py-plugins in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from jupytext) (0.4.2)\n",
      "\u001b[32m+          Requirement already satisfied: nbformat in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from jupytext) (5.10.4)\n",
      "\u001b[32m+          Requirement already satisfied: packaging in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from jupytext) (21.3)\n",
      "\u001b[32m+          Requirement already satisfied: pyyaml in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from jupytext) (6.0.2)\n",
      "\u001b[32m+          Requirement already satisfied: tomli in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from jupytext) (2.0.1)\n",
      "\u001b[32m+          Requirement already satisfied: mdurl~=0.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from markdown-it-py>=1.0->jupytext) (0.1.2)\n",
      "\u001b[32m+          Requirement already satisfied: fastjsonschema>=2.15 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from nbformat->jupytext) (2.20.0)\n",
      "\u001b[32m+          Requirement already satisfied: jsonschema>=2.6 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from nbformat->jupytext) (4.23.0)\n",
      "\u001b[32m+          Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from nbformat->jupytext) (5.7.2)\n",
      "\u001b[32m+          Requirement already satisfied: traitlets>=5.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from nbformat->jupytext) (5.14.3)\n",
      "\u001b[32m+          Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from packaging->jupytext) (3.1.4)\n",
      "\u001b[32m+          Requirement already satisfied: attrs>=22.2.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat->jupytext) (23.2.0)\n",
      "\u001b[32m+          Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat->jupytext) (2023.12.1)\n",
      "\u001b[32m+          Requirement already satisfied: referencing>=0.28.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat->jupytext) (0.35.1)\n",
      "\u001b[32m+          Requirement already satisfied: rpds-py>=0.7.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat->jupytext) (0.20.0)\n",
      "\u001b[32m+          Requirement already satisfied: platformdirs>=2.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from jupyter-core!=5.0.*,>=4.12->nbformat->jupytext) (4.3.6)\n",
      "\u001b[32m+  markdown cell:\n",
      "\u001b[32m+    id: fb184d37-9aed-45e2-b6ee-b575695be87e\n",
      "\u001b[32m+    source:\n",
      "\u001b[32m+      1. **Run the following command** in a notebook cell to convert the current notebook to a `.py` file:\n",
      "\u001b[32m+      \n",
      "\u001b[32m+      This command will create a `.py` file in the same directory as the notebook.\n",
      "\u001b[32m+  code cell:\n",
      "\u001b[32m+    id: 6be6b34e-945b-4458-9c13-20be0c24e07b\n",
      "\u001b[32m+    execution_count: 69\n",
      "\u001b[32m+    metadata (known keys):\n",
      "\u001b[32m+      tags:\n",
      "\u001b[32m+        []\n",
      "\u001b[32m+    source:\n",
      "\u001b[32m+      # Replace 'your_notebook.ipynb' with your actual notebook filename\n",
      "\u001b[32m+      !jupytext --to py 03_Data-storage-and-access-via-buckets.ipynb\n",
      "\u001b[32m+    outputs:\n",
      "\u001b[32m+      output 0:\n",
      "\u001b[32m+        output_type: stream\n",
      "\u001b[32m+        name: stdout\n",
      "\u001b[32m+        text:\n",
      "\u001b[32m+          [jupytext] Reading 03_Data-storage-and-access-via-buckets.ipynb in format ipynb\n",
      "\u001b[32m+          [jupytext] Writing 03_Data-storage-and-access-via-buckets.py (destination file replaced)\n",
      "\u001b[32m+  markdown cell:\n",
      "\u001b[32m+    id: 3a7c40ca-6471-4ede-8962-f37d9fb9cf93\n",
      "\u001b[32m+    source:\n",
      "\u001b[32m+      ### Method 2: Automated Script for Converting All Notebooks in a Directory\n",
      "\u001b[32m+      \n",
      "\u001b[32m+      If you have multiple notebooks to convert, you can automate the conversion process by running this script, which converts all `.ipynb` files in the current directory to `.py` files:\n",
      "\u001b[32m+  code cell:\n",
      "\u001b[32m+    id: ac899c70-e387-492d-b8eb-64c759faef9d\n",
      "\u001b[32m+    execution_count: 70\n",
      "\u001b[32m+    metadata (known keys):\n",
      "\u001b[32m+      tags:\n",
      "\u001b[32m+        []\n",
      "\u001b[32m+    source:\n",
      "\u001b[32m+      import subprocess\n",
      "\u001b[32m+      import os\n",
      "\u001b[32m+      \n",
      "\u001b[32m+      # List all .ipynb files in the directory\n",
      "\u001b[32m+      notebooks = [f for f in os.listdir() if f.endswith('.ipynb')]\n",
      "\u001b[32m+      \n",
      "\u001b[32m+      # Convert each notebook to .py using jupytext\n",
      "\u001b[32m+      for notebook in notebooks:\n",
      "\u001b[32m+          output_file = notebook.replace('.ipynb', '.py')\n",
      "\u001b[32m+          subprocess.run([\"jupytext\", \"--to\", \"py\", notebook, \"--output\", output_file])\n",
      "\u001b[32m+          print(f\"Converted {notebook} to {output_file}\")\n",
      "\u001b[32m+    outputs:\n",
      "\u001b[32m+      output 0:\n",
      "\u001b[32m+        output_type: stream\n",
      "\u001b[32m+        name: stdout\n",
      "\u001b[32m+        text:\n",
      "\u001b[32m+          [jupytext] Reading 05_Intro-train-models.ipynb in format ipynb\n",
      "\u001b[32m+          [jupytext] Writing 05_Intro-train-models.py\n",
      "\u001b[32m+          Converted 05_Intro-train-models.ipynb to 05_Intro-train-models.py\n",
      "\u001b[32m+          [jupytext] Reading 03_Data-storage-and-access-via-buckets.ipynb in format ipynb\n",
      "\u001b[32m+          [jupytext] Updating the timestamp of 03_Data-storage-and-access-via-buckets.py\n",
      "\u001b[32m+          Converted 03_Data-storage-and-access-via-buckets.ipynb to 03_Data-storage-and-access-via-buckets.py\n",
      "\u001b[32m+          [jupytext] Reading 03_Data-storage-and-access-via-buckets-test.ipynb in format ipynb\n",
      "\u001b[32m+          [jupytext] Writing 03_Data-storage-and-access-via-buckets-test.py\n",
      "\u001b[32m+          Converted 03_Data-storage-and-access-via-buckets-test.ipynb to 03_Data-storage-and-access-via-buckets-test.py\n",
      "\u001b[32m+          [jupytext] Reading 06_Hyperparameter-tuning.ipynb in format ipynb\n",
      "\u001b[32m+          [jupytext] Writing 06_Hyperparameter-tuning.py\n",
      "\u001b[32m+          Converted 06_Hyperparameter-tuning.ipynb to 06_Hyperparameter-tuning.py\n",
      "\u001b[32m+          [jupytext] Reading create_large_data.ipynb in format ipynb\n",
      "\u001b[32m+          [jupytext] Writing create_large_data.py\n",
      "\u001b[32m+          Converted create_large_data.ipynb to create_large_data.py\n",
      "\u001b[32m+          [jupytext] Reading 04_Interacting-with-code-repo.ipynb in format ipynb\n",
      "\u001b[32m+          [jupytext] Writing 04_Interacting-with-code-repo.py\n",
      "\u001b[32m+          Converted 04_Interacting-with-code-repo.ipynb to 04_Interacting-with-code-repo.py\n",
      "\u001b[32m+  markdown cell:\n",
      "\u001b[32m+    id: 3ae6408a-7501-4239-abdb-d45da78472b7\n",
      "\u001b[32m+    source:\n",
      "\u001b[32m+      ### Adding .ipynb to gitigore\n",
      "\u001b[32m+      \n",
      "\u001b[32m+      Adding `.ipynb` files to `.gitignore` is a good practice if you plan to only commit `.py` scripts. This will prevent accidental commits of Jupyter Notebook files across all subfolders in the repository.\n",
      "\u001b[32m+      \n",
      "\u001b[32m+      Here’s how to add `.ipynb` files to `.gitignore` to ignore them project-wide:\n",
      "\u001b[32m+      \n",
      "\u001b[32m+      1. **Open or Create the `.gitignore` File**:\n",
      "\u001b[32m+      \n",
      "\u001b[32m+          ```python\n",
      "\u001b[32m+          !ls -a # check for existing .gitignore file\n",
      "\u001b[32m+          ```\n",
      "\u001b[32m+          \n",
      "\u001b[32m+         - If you don’t already have a `.gitignore` file in the repository root (use '!ls -a' to check, you can create one by running:\n",
      "\u001b[32m+         \n",
      "\u001b[32m+           ```python\n",
      "\u001b[32m+           !touch .gitignore\n",
      "\u001b[32m+           ```\n",
      "\u001b[32m+      \n",
      "\u001b[32m+      \n",
      "\u001b[32m+      2. **Add `.ipynb` Files to `.gitignore`**:\n",
      "\u001b[32m+      \n",
      "\u001b[32m+         - Append the following line to your `.gitignore` file to ignore all `.ipynb` files in all folders:\n",
      "\u001b[32m+      \n",
      "\u001b[32m+           ```plaintext\n",
      "\u001b[32m+           *.ipynb # Ignore all Jupyter Notebook files\n",
      "\u001b[32m+           ```\n",
      "\u001b[32m+      \n",
      "\u001b[32m+         - You can add this line using a command within your notebook:\n",
      "\u001b[32m+         \n",
      "\u001b[32m+           ```python\n",
      "\u001b[32m+           with open(\".gitignore\", \"a\") as gitignore:\n",
      "\u001b[32m+               gitignore.write(\"\\n# Ignore all Jupyter Notebook files\\n*.ipynb\\n\")\n",
      "\u001b[32m+           ```\n",
      "\u001b[32m+      \n",
      "\u001b[32m+      \n",
      "\u001b[32m+      \n",
      "\u001b[32m+      3. **Verify and Commit the `.gitignore` File**:\n",
      "\u001b[32m+      \n",
      "\u001b[32m+         - Add and commit the updated `.gitignore` file to ensure it’s applied across the repository.\n",
      "\u001b[32m+      \n",
      "\u001b[32m+           ```python\n",
      "\u001b[32m+           !git add .gitignore\n",
      "\u001b[32m+           !git commit -m \"Add .ipynb files to .gitignore to ignore notebooks\"\n",
      "\u001b[32m+           !git push origin main\n",
      "\u001b[32m+           ```\n",
      "\u001b[32m+      \n",
      "\u001b[32m+      This setup will:\n",
      "\u001b[32m+      - Prevent all `.ipynb` files from being tracked by Git.\n",
      "\u001b[32m+      - Keep your repository cleaner, containing only `.py` scripts for easier version control and reduced repository size. \n",
      "\u001b[32m+      \n",
      "\u001b[32m+      Now any new or existing notebooks won’t show up as untracked files in Git, ensuring your commits stay focused on the converted `.py` files.\n",
      "\u001b[32m+  markdown cell:\n",
      "\u001b[32m+    id: 16a6a553-8ef4-416a-9978-82d2ab8e3b2e\n",
      "\u001b[32m+    source:\n",
      "\u001b[32m+      ### converting back to jupyter notebook (after pulling repo in for fresh day of work)\n",
      "\u001b[32m+      To convert a `.py` script to a `.ipynb` notebook, you can use **jupytext**, which is designed to convert between Jupyter Notebooks and Python scripts more seamlessly.\n",
      "\u001b[32m+      \n",
      "\u001b[32m+      \n",
      "\u001b[32m+  markdown cell:\n",
      "\u001b[32m+    id: 75190b0a-1b1d-4bdb-a814-be7570a98c12\n",
      "\u001b[32m+    source:\n",
      "\u001b[32m+      2. **Convert the `.py` file to a `.ipynb` notebook**:\n",
      "\u001b[32m+      \n",
      "\u001b[32m+      This command will create `03_Data-storage-and-access-via-buckets-test.ipynb` in the current directory, converting the Python script to a Jupyter Notebook format. Jupytext handles the conversion gracefully without expecting the `.py` file to be in JSON format.\n",
      "\u001b[32m+  code cell:\n",
      "\u001b[32m+    id: 48e812c7-45f4-4adf-9bd3-1dcbc59e9052\n",
      "\u001b[32m+    execution_count: 67\n",
      "\u001b[32m+    metadata (known keys):\n",
      "\u001b[32m+      tags:\n",
      "\u001b[32m+        []\n",
      "\u001b[32m+    source:\n",
      "\u001b[32m+      # Replace 'your_script.py' with your actual filename\n",
      "\u001b[32m+      !jupytext --to notebook 03_Data-storage-and-access-via-buckets.py --output 03_Data-storage-and-access-via-buckets-test.ipynb\n",
      "\u001b[32m+    outputs:\n",
      "\u001b[32m+      output 0:\n",
      "\u001b[32m+        output_type: stream\n",
      "\u001b[32m+        name: stdout\n",
      "\u001b[32m+        text:\n",
      "\u001b[32m+          [jupytext] Reading 03_Data-storage-and-access-via-buckets.py in format py\n",
      "\u001b[32m+          [jupytext] Writing 03_Data-storage-and-access-via-buckets-test.ipynb\n",
      "\u001b[32m+  code cell:\n",
      "\u001b[32m+    id: a9d83d2d-a6ab-42e1-9510-f3bed99468fe\n",
      "\u001b[32m+  code cell:\n",
      "\u001b[32m+    id: 7214283a-c1c8-48c0-a6c3-52d9b6566238\n",
      "\u001b[32m+    execution_count: 64\n",
      "\u001b[32m+    metadata (known keys):\n",
      "\u001b[32m+      tags:\n",
      "\u001b[32m+        []\n",
      "\u001b[32m+    source:\n",
      "\u001b[32m+      # Convert your_script.py to a new notebook named new_notebook.ipynb\n",
      "\u001b[32m+      # !jupyter nbconvert --to notebook your_script.py --output new_notebook\n",
      "\u001b[32m+      \n",
      "\u001b[32m+      !jupyter nbconvert --to notebook 03_Data-storage-and-access-via-buckets.py --output 03_Data-storage-and-access-via-buckets-test\n",
      "\u001b[32m+    outputs:\n",
      "\u001b[32m+      output 0:\n",
      "\u001b[32m+        output_type: stream\n",
      "\u001b[32m+        name: stdout\n",
      "\u001b[32m+        text:\n",
      "\u001b[32m+          [NbConvertApp] Converting notebook 03_Data-storage-and-access-via-buckets.py to notebook\n",
      "\u001b[32m+          Traceback (most recent call last):\n",
      "\u001b[32m+            File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/nbformat/reader.py\", line 19, in parse_json\n",
      "\u001b[32m+              nb_dict = json.loads(s, **kwargs)\n",
      "\u001b[32m+            File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/json/__init__.py\", line 346, in loads\n",
      "\u001b[32m+              return _default_decoder.decode(s)\n",
      "\u001b[32m+            File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/json/decoder.py\", line 337, in decode\n",
      "\u001b[32m+              obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n",
      "\u001b[32m+            File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/json/decoder.py\", line 355, in raw_decode\n",
      "\u001b[32m+              raise JSONDecodeError(\"Expecting value\", s, err.value) from None\n",
      "\u001b[32m+          json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
      "\u001b[32m+          \n",
      "\u001b[32m+          The above exception was the direct cause of the following exception:\n",
      "\u001b[32m+          \n",
      "\u001b[32m+          Traceback (most recent call last):\n",
      "\u001b[32m+            File \"/home/ec2-user/anaconda3/envs/python3/bin/jupyter-nbconvert\", line 10, in <module>\n",
      "\u001b[32m+              sys.exit(main())\n",
      "\u001b[32m+            File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/jupyter_core/application.py\", line 283, in launch_instance\n",
      "\u001b[32m+              super().launch_instance(argv=argv, **kwargs)\n",
      "\u001b[32m+            File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "\u001b[32m+              app.start()\n",
      "\u001b[32m+            File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/nbconvert/nbconvertapp.py\", line 420, in start\n",
      "\u001b[32m+              self.convert_notebooks()\n",
      "\u001b[32m+            File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/nbconvert/nbconvertapp.py\", line 597, in convert_notebooks\n",
      "\u001b[32m+              self.convert_single_notebook(notebook_filename)\n",
      "\u001b[32m+            File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/nbconvert/nbconvertapp.py\", line 563, in convert_single_notebook\n",
      "\u001b[32m+              output, resources = self.export_single_notebook(\n",
      "\u001b[32m+            File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/nbconvert/nbconvertapp.py\", line 487, in export_single_notebook\n",
      "\u001b[32m+              output, resources = self.exporter.from_filename(\n",
      "\u001b[32m+            File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/nbconvert/exporters/exporter.py\", line 201, in from_filename\n",
      "\u001b[32m+              return self.from_file(f, resources=resources, **kw)\n",
      "\u001b[32m+            File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/nbconvert/exporters/exporter.py\", line 221, in from_file\n",
      "\u001b[32m+              nbformat.read(file_stream, as_version=4), resources=resources, **kw\n",
      "\u001b[32m+            File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/nbformat/__init__.py\", line 174, in read\n",
      "\u001b[32m+              return reads(buf, as_version, capture_validation_error, **kwargs)\n",
      "\u001b[32m+            File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/nbformat/__init__.py\", line 92, in reads\n",
      "\u001b[32m+              nb = reader.reads(s, **kwargs)\n",
      "\u001b[32m+            File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/nbformat/reader.py\", line 75, in reads\n",
      "\u001b[32m+              nb_dict = parse_json(s, **kwargs)\n",
      "\u001b[32m+            File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/nbformat/reader.py\", line 25, in parse_json\n",
      "\u001b[32m+              raise NotJSONError(message) from e\n",
      "\u001b[32m+          nbformat.reader.NotJSONError: Notebook does not appear to be JSON: '#!/usr/bin/env python\\n# coding: utf-8\\...\n",
      "\n",
      "\u001b[0m\u001b[34m\u001b[1m## replaced /cells/11/execution_count:\u001b[0m\n",
      "\u001b[31m-  53\n",
      "\u001b[32m+  55\n",
      "\n",
      "\u001b[0m\u001b[34m\u001b[1m## inserted before /cells/11/outputs/0:\u001b[0m\n",
      "\u001b[32m+  output:\n",
      "\u001b[32m+    output_type: stream\n",
      "\u001b[32m+    name: stdout\n",
      "\u001b[32m+    text:\n",
      "\u001b[32m+      [main 0363cc2] Added updates from Jupyter notebook\n",
      "\u001b[32m+       7 files changed, 416 insertions(+), 91 deletions(-)\n",
      "\u001b[32m+       delete mode 100644 00_Data-storage-and-access-via-buckets.ipynb\n",
      "\u001b[32m+       create mode 100644 01_Setting-up-S3-bucket.md\n",
      "\u001b[32m+       create mode 100644 02_Setting-up-notebook-environment.md\n",
      "\u001b[32m+       create mode 100644 03_Data-storage-and-access-via-buckets.ipynb\n",
      "\u001b[32m+       rename push-git-updates.ipynb => 04_Interacting-with-code-repo.ipynb (77%)\n",
      "\u001b[32m+       rename 01_Intro-train-models.ipynb => 05_Intro-train-models.ipynb (100%)\n",
      "\u001b[32m+       rename 02_Hyperparameter-tuning.ipynb => 06_Hyperparameter-tuning.ipynb (100%)\n",
      "\n",
      "\u001b[0m\u001b[34m\u001b[1m## deleted /cells/11/outputs/0:\u001b[0m\n",
      "\u001b[31m-  output:\n",
      "\u001b[31m-    output_type: stream\n",
      "\u001b[31m-    name: stdout\n",
      "\u001b[31m-    text:\n",
      "\u001b[31m-      [main 637d64c] Added updates from Jupyter notebook\n",
      "\u001b[31m-       1 file changed, 19 insertions(+), 27 deletions(-)\n",
      "\n",
      "\u001b[0m\u001b[34m\u001b[1m## modified /cells/11/source:\u001b[0m\n",
      "\u001b[36m@@ -1,2 +1,2 @@\u001b[m\n",
      "\u001b[31m-!git add .\u001b[m\n",
      "\u001b[31m-!git commit -m \"Added updates from Jupyter notebook\"\u001b[m\n",
      "\u001b[32m+\u001b[m\u001b[32m!git add . # you may also add files one at a time, for further specificity over the associated commit message\u001b[m\n",
      "\u001b[32m+\u001b[m\u001b[32m!git commit -m \"Updates from Jupyter notebooks\" # in general, your commit message should be more specific!\u001b[m\n",
      "\n",
      "\u001b[0m\u001b[34m\u001b[1m## replaced /cells/13/execution_count:\u001b[0m\n",
      "\u001b[31m-  51\n",
      "\u001b[32m+  56\n",
      "\n",
      "\u001b[0m\u001b[34m\u001b[1m## inserted before /cells/13/outputs/0:\u001b[0m\n",
      "\u001b[32m+  output:\n",
      "\u001b[32m+    output_type: stream\n",
      "\u001b[32m+    name: stdout\n",
      "\u001b[32m+    text:\n",
      "\u001b[32m+      From https://github.com/UW-Madison-DataScience/test_AWS\n",
      "\u001b[32m+       * branch            main       -> FETCH_HEAD\n",
      "\u001b[32m+         adfe7b1..637d64c  main       -> origin/main\n",
      "\u001b[32m+      Already up to date.\n",
      "\n",
      "\u001b[0m\u001b[34m\u001b[1m## deleted /cells/13/outputs/0:\u001b[0m\n",
      "\u001b[31m-  output:\n",
      "\u001b[31m-    output_type: stream\n",
      "\u001b[31m-    name: stdout\n",
      "\u001b[31m-    text:\n",
      "\u001b[31m-      remote: Enumerating objects: 7, done.\u001b[K\n",
      "\u001b[31m-      remote: Counting objects: 100% (7/7), done.\u001b[K\n",
      "\u001b[31m-      remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
      "\u001b[31m-      remote: Total 6 (delta 2), reused 3 (delta 1), pack-reused 0 (from 0)\u001b[K\n",
      "\u001b[31m-      Unpacking objects: 100% (6/6), 1.18 KiB | 1.18 MiB/s, done.\n",
      "\u001b[31m-      From https://github.com/UW-Madison-DataScience/test_AWS\n",
      "\u001b[31m-       * branch            main       -> FETCH_HEAD\n",
      "\u001b[31m-         ebe991c..adfe7b1  main       -> origin/main\n",
      "\u001b[31m-      Updating 2ff6cf0..adfe7b1\n",
      "\u001b[31m-      Fast-forward\n",
      "\u001b[31m-       .gitignore                                         |    3 \u001b[32m+\u001b[m\n",
      "\u001b[31m-       ...storage-and-access-via-buckets-checkpoint.ipynb |    6 \u001b[31m-\u001b[m\n",
      "\u001b[31m-       .../01_Intro-train-models-checkpoint.ipynb         | 2555 \u001b[31m--------------------\u001b[m\n",
      "\u001b[31m-       .../02_Hyperparameter-tuning-checkpoint.ipynb      |  470 \u001b[31m----\u001b[m\n",
      "\u001b[31m-       .../create_large_data-checkpoint.ipynb             |   54 \u001b[31m-\u001b[m\n",
      "\u001b[31m-       .../push-git-updates-checkpoint.ipynb              |  322 \u001b[31m---\u001b[m\n",
      "\u001b[31m-       .ipynb_checkpoints/train_nn-checkpoint.py          |   93 \u001b[31m-\u001b[m\n",
      "\u001b[31m-       .ipynb_checkpoints/train_xgboost-checkpoint.py     |   65 \u001b[31m-\u001b[m\n",
      "\u001b[31m-       __pycache__/train_xgboost.cpython-310.pyc          |  Bin \u001b[31m2194\u001b[m -> \u001b[32m0\u001b[m bytes\n",
      "\u001b[31m-       9 files changed, 3 insertions(+), 3565 deletions(-)\n",
      "\u001b[31m-       create mode 100644 .gitignore\n",
      "\u001b[31m-       delete mode 100644 .ipynb_checkpoints/00_Data-storage-and-access-via-buckets-checkpoint.ipynb\n",
      "\u001b[31m-       delete mode 100644 .ipynb_checkpoints/01_Intro-train-models-checkpoint.ipynb\n",
      "\u001b[31m-       delete mode 100644 .ipynb_checkpoints/02_Hyperparameter-tuning-checkpoint.ipynb\n",
      "\u001b[31m-       delete mode 100644 .ipynb_checkpoints/create_large_data-checkpoint.ipynb\n",
      "\u001b[31m-       delete mode 100644 .ipynb_checkpoints/push-git-updates-checkpoint.ipynb\n",
      "\u001b[31m-       delete mode 100644 .ipynb_checkpoints/train_nn-checkpoint.py\n",
      "\u001b[31m-       delete mode 100644 .ipynb_checkpoints/train_xgboost-checkpoint.py\n",
      "\u001b[31m-       delete mode 100644 __pycache__/train_xgboost.cpython-310.pyc\n",
      "\n",
      "\u001b[0m\u001b[34m\u001b[1m## replaced /cells/17/execution_count:\u001b[0m\n",
      "\u001b[31m-  54\n",
      "\u001b[32m+  57\n",
      "\n",
      "\u001b[0m\u001b[34m\u001b[1m## modified /cells/17/outputs/0/text:\u001b[0m\n",
      "\u001b[36m@@ -1,9 +1,9 @@\u001b[m\n",
      "\u001b[31m-Enumerating objects: 5, done.\u001b[m\n",
      "\u001b[31m-Counting objects: 100% (5/5), done.\u001b[m\n",
      "\u001b[32m+\u001b[m\u001b[32mEnumerating objects: 7, done.\u001b[m\n",
      "\u001b[32m+\u001b[m\u001b[32mCounting objects: 100% (7/7), done.\u001b[m\n",
      " Delta compression using up to 2 threads\u001b[m\n",
      "\u001b[31m-Compressing objects: 100% (3/3), done.\u001b[m\n",
      "\u001b[31m-Writing objects: 100% (3/3), 780 bytes | 780.00 KiB/s, done.\u001b[m\n",
      "\u001b[31m-Total 3 (delta 2), reused 0 (delta 0), pack-reused 0\u001b[m\n",
      "\u001b[31m-remote: Resolving deltas: 100% (2/2), completed with 2 local objects.\u001b[K\u001b[m\n",
      "\u001b[32m+\u001b[m\u001b[32mCompressing objects: 100% (6/6), done.\u001b[m\n",
      "\u001b[32m+\u001b[m\u001b[32mWriting objects: 100% (6/6), 11.22 KiB | 5.61 MiB/s, done.\u001b[m\n",
      "\u001b[32m+\u001b[m\u001b[32mTotal 6 (delta 1), reused 0 (delta 0), pack-reused 0\u001b[m\n",
      "\u001b[32m+\u001b[m\u001b[32mremote: Resolving deltas: 100% (1/1), completed with 1 local object.\u001b[K\u001b[m\n",
      " To https://github.com/UW-Madison-DataScience/test_AWS.git\u001b[m\n",
      "\u001b[31m-   adfe7b1..637d64c  main -> main\u001b[m\n",
      "\u001b[32m+\u001b[m\u001b[32m   637d64c..0363cc2  main -> main\u001b[m\n",
      "\n",
      "\u001b[0m\u001b[34m\u001b[1m## deleted /cells/18:\u001b[0m\n",
      "\u001b[31m-  code cell:\n",
      "\u001b[31m-    id: 34b627ea-b2e4-439f-91e9-4dc2b0244aeb\n",
      "\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!git diff "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65f534e-4947-4078-80ab-6f21af394826",
   "metadata": {},
   "source": [
    "### 3. Convert json ipynb files to .py\n",
    "\n",
    "To avoid tracking ipynb files directly, which are formatted as json, we may want to convert our notebook to .py first (plain text). This will make it easier to see our code edits across commits. Otherwise, each small edit will have massive changes associated with it.\n",
    "\n",
    "#### Benefits of converting to `.py` before Committing\n",
    "\n",
    "- **Cleaner Version Control**: `.py` files have cleaner diffs and are easier to review and merge in Git.\n",
    "- **Script Compatibility**: Python files are more compatible with other environments and can run easily from the command line.\n",
    "- **Reduced Repository Size**: `.py` files are generally lighter than `.ipynb` files since they don’t store outputs or metadata.\n",
    "\n",
    "Converting notebooks to `.py` files helps streamline the workflow for both collaborative projects and deployments. This approach also maintains code readability and minimizes potential issues with notebook-specific metadata in Git history. Here’s how to convert `.ipynb` files to `.py` in SageMaker without needing to export or download files:\n",
    "\n",
    "#### Method 1: Using JupyText\n",
    "\n",
    "1. **Install Jupytext** (if you haven’t already):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "2cb6345d-16b7-44af-b026-98abe4a060a7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: jupytext in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (1.16.4)\n",
      "Requirement already satisfied: markdown-it-py>=1.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from jupytext) (3.0.0)\n",
      "Requirement already satisfied: mdit-py-plugins in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from jupytext) (0.4.2)\n",
      "Requirement already satisfied: nbformat in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from jupytext) (5.10.4)\n",
      "Requirement already satisfied: packaging in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from jupytext) (21.3)\n",
      "Requirement already satisfied: pyyaml in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from jupytext) (6.0.2)\n",
      "Requirement already satisfied: tomli in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from jupytext) (2.0.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from markdown-it-py>=1.0->jupytext) (0.1.2)\n",
      "Requirement already satisfied: fastjsonschema>=2.15 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from nbformat->jupytext) (2.20.0)\n",
      "Requirement already satisfied: jsonschema>=2.6 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from nbformat->jupytext) (4.23.0)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from nbformat->jupytext) (5.7.2)\n",
      "Requirement already satisfied: traitlets>=5.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from nbformat->jupytext) (5.14.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from packaging->jupytext) (3.1.4)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat->jupytext) (23.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat->jupytext) (2023.12.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat->jupytext) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat->jupytext) (0.20.0)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from jupyter-core!=5.0.*,>=4.12->nbformat->jupytext) (4.3.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install jupytext\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb184d37-9aed-45e2-b6ee-b575695be87e",
   "metadata": {},
   "source": [
    "1. **Run the following command** in a notebook cell to convert the current notebook to a `.py` file:\n",
    "\n",
    "This command will create a `.py` file in the same directory as the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "6be6b34e-945b-4458-9c13-20be0c24e07b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[jupytext] Reading 03_Data-storage-and-access-via-buckets.ipynb in format ipynb\n",
      "[jupytext] Updating the timestamp of 03_Data-storage-and-access-via-buckets.py\n"
     ]
    }
   ],
   "source": [
    "# Replace 'your_notebook.ipynb' with your actual notebook filename\n",
    "!jupytext --to py 03_Data-storage-and-access-via-buckets.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7c40ca-6471-4ede-8962-f37d9fb9cf93",
   "metadata": {},
   "source": [
    "#### Method 2: Automated Script for Converting All Notebooks in a Directory\n",
    "\n",
    "If you have multiple notebooks to convert, you can automate the conversion process by running this script, which converts all `.ipynb` files in the current directory to `.py` files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ac899c70-e387-492d-b8eb-64c759faef9d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[jupytext] Reading 05_Intro-train-models.ipynb in format ipynb\n",
      "[jupytext] Updating the timestamp of 05_Intro-train-models.py\n",
      "Converted 05_Intro-train-models.ipynb to 05_Intro-train-models.py\n",
      "[jupytext] Reading 03_Data-storage-and-access-via-buckets.ipynb in format ipynb\n",
      "[jupytext] Updating the timestamp of 03_Data-storage-and-access-via-buckets.py\n",
      "Converted 03_Data-storage-and-access-via-buckets.ipynb to 03_Data-storage-and-access-via-buckets.py\n",
      "[jupytext] Reading 03_Data-storage-and-access-via-buckets-test.ipynb in format ipynb\n",
      "[jupytext] Updating the timestamp of 03_Data-storage-and-access-via-buckets-test.py\n",
      "Converted 03_Data-storage-and-access-via-buckets-test.ipynb to 03_Data-storage-and-access-via-buckets-test.py\n",
      "[jupytext] Reading 06_Hyperparameter-tuning.ipynb in format ipynb\n",
      "[jupytext] Updating the timestamp of 06_Hyperparameter-tuning.py\n",
      "Converted 06_Hyperparameter-tuning.ipynb to 06_Hyperparameter-tuning.py\n",
      "[jupytext] Reading create_large_data.ipynb in format ipynb\n",
      "[jupytext] Updating the timestamp of create_large_data.py\n",
      "Converted create_large_data.ipynb to create_large_data.py\n",
      "[jupytext] Reading 04_Interacting-with-code-repo.ipynb in format ipynb\n",
      "[jupytext] Writing 04_Interacting-with-code-repo.py (destination file replaced)\n",
      "Converted 04_Interacting-with-code-repo.ipynb to 04_Interacting-with-code-repo.py\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import os\n",
    "\n",
    "# List all .ipynb files in the directory\n",
    "notebooks = [f for f in os.listdir() if f.endswith('.ipynb')]\n",
    "\n",
    "# Convert each notebook to .py using jupytext\n",
    "for notebook in notebooks:\n",
    "    output_file = notebook.replace('.ipynb', '.py')\n",
    "    subprocess.run([\"jupytext\", \"--to\", \"py\", notebook, \"--output\", output_file])\n",
    "    print(f\"Converted {notebook} to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae6408a-7501-4239-abdb-d45da78472b7",
   "metadata": {},
   "source": [
    "### 4. Adding .ipynb to gitigore\n",
    "\n",
    "Adding `.ipynb` files to `.gitignore` is a good practice if you plan to only commit `.py` scripts. This will prevent accidental commits of Jupyter Notebook files across all subfolders in the repository.\n",
    "\n",
    "Here’s how to add `.ipynb` files to `.gitignore` to ignore them project-wide:\n",
    "\n",
    "1. **Open or Create the `.gitignore` File**:\n",
    "\n",
    "    ```python\n",
    "    !ls -a # check for existing .gitignore file\n",
    "    ```\n",
    "    \n",
    "   - If you don’t already have a `.gitignore` file in the repository root (use '!ls -a' to check, you can create one by running:\n",
    "   \n",
    "     ```python\n",
    "     !touch .gitignore\n",
    "     ```\n",
    "\n",
    "\n",
    "2. **Add `.ipynb` Files to `.gitignore`**:\n",
    "\n",
    "   - Append the following line to your `.gitignore` file to ignore all `.ipynb` files in all folders:\n",
    "\n",
    "     ```plaintext\n",
    "     *.ipynb # Ignore all Jupyter Notebook files\n",
    "     ```\n",
    "\n",
    "   - You can add this line using a command within your notebook:\n",
    "   \n",
    "     ```python\n",
    "     with open(\".gitignore\", \"a\") as gitignore:\n",
    "         gitignore.write(\"\\n# Ignore all Jupyter Notebook files\\n*.ipynb\\n\")\n",
    "     ```\n",
    "\n",
    "\n",
    "\n",
    "3. **Verify and Commit the `.gitignore` File**:\n",
    "\n",
    "   - Add and commit the updated `.gitignore` file to ensure it’s applied across the repository.\n",
    "\n",
    "     ```python\n",
    "     !git add .gitignore\n",
    "     !git commit -m \"Add .ipynb files to .gitignore to ignore notebooks\"\n",
    "     !git push origin main\n",
    "     ```\n",
    "\n",
    "This setup will:\n",
    "- Prevent all `.ipynb` files from being tracked by Git.\n",
    "- Keep your repository cleaner, containing only `.py` scripts for easier version control and reduced repository size. \n",
    "\n",
    "Now any new or existing notebooks won’t show up as untracked files in Git, ensuring your commits stay focused on the converted `.py` files."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c87d7e0-e14e-4b04-a5a2-5ac742e6b467",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "2. **Add and Commit Changes**:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "1681c48e-9d03-490a-ae4c-2ae84275c7ee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[main bc28ce1] Updates from Jupyter notebooks\n",
      " 1 file changed, 875 insertions(+), 56 deletions(-)\n"
     ]
    }
   ],
   "source": [
    "!git add . # you may also add files one at a time, for further specificity over the associated commit message\n",
    "!git commit -m \"Updates from Jupyter notebooks\" # in general, your commit message should be more specific!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cebecd0-9f39-43c6-8efa-070c7748c52c",
   "metadata": {
    "tags": []
   },
   "source": [
    "3. **Pull the Latest Changes from the Main Branch**: Pull the latest changes from the remote main branch to ensure your local branch is up-to-date.\n",
    "\n",
    "    Recommended: Set the Pull Strategy for this Repository (Merge by Default)\n",
    "\n",
    "    All options:\n",
    "\n",
    "    * Merge (pull.rebase false): Combines the remote changes into your local branch as a merge commit.\n",
    "    * Rebase (pull.rebase true): Replays your local changes on top of the updated main branch, resulting in a linear history.\n",
    "    * Fast-forward only (pull.ff only): Only pulls if the local branch can fast-forward to the remote without diverging (no new commits locally)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "144840f8-9733-4888-99d4-3b04c12458ee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From https://github.com/UW-Madison-DataScience/test_AWS\n",
      " * branch            main       -> FETCH_HEAD\n",
      "   637d64c..0363cc2  main       -> origin/main\n",
      "Already up to date.\n"
     ]
    }
   ],
   "source": [
    "!git config pull.rebase false # Combines the remote changes into your local branch as a merge commit.\n",
    "\n",
    "!git pull origin main\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a20ad564-df9f-4484-b39f-771f57e99123",
   "metadata": {},
   "source": [
    "If you get merge conflicts, be sure to resolve those before moving forward (e.g., use git checkout -> add -> commit). You can skip the below code if you don't have any conflicts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "31ed04f1-6a2d-4d04-bda9-cdd9dc8f84ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Keep your local changes in one conflicting file\n",
    "# !git checkout --ours train_nn.py\n",
    "\n",
    "# Keep remote version for the other conflicting file\n",
    "# !git checkout --theirs train_xgboost.py\n",
    "\n",
    "# # Stage the files to mark the conflicts as resolved\n",
    "# !git add train_nn.py\n",
    "# !git add train_xgboost.py\n",
    "\n",
    "# # Commit the merge result\n",
    "# !git commit -m \"Resolved merge conflicts by keeping local changes\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dfce6eb-ee29-48bd-9895-56b0abf4b3e7",
   "metadata": {},
   "source": [
    "4. **Push Changes and Enter Credentials**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "86cd209c-9b93-488e-a159-f6f65f94511c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enumerating objects: 5, done.\n",
      "Counting objects: 100% (5/5), done.\n",
      "Delta compression using up to 2 threads\n",
      "Compressing objects: 100% (3/3), done.\n",
      "Writing objects: 100% (3/3), 10.51 KiB | 5.25 MiB/s, done.\n",
      "Total 3 (delta 1), reused 0 (delta 0), pack-reused 0\n",
      "remote: Resolving deltas: 100% (1/1), completed with 1 local object.\u001b[K\n",
      "To https://github.com/UW-Madison-DataScience/test_AWS.git\n",
      "   0363cc2..bc28ce1  main -> main\n"
     ]
    }
   ],
   "source": [
    "# Push with embedded credentials from getpass (avoids interactive prompt)\n",
    "!git push https://{username}:{token}@{github_url} main\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43658069-6085-4680-aacc-c91155625e88",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Step 5: Pulling .py files and converting back to notebook format\n",
    "\n",
    "### 5. Converting back to jupyter notebook (after pulling repo in for fresh day of work)\n",
    "To convert a `.py` script to a `.ipynb` notebook, you can use **jupytext**, which is designed to convert between Jupyter Notebooks and Python scripts more seamlessly.\n",
    "\n",
    "This command will create `03_Data-storage-and-access-via-buckets-test.ipynb` in the current directory, converting the Python script to a Jupyter Notebook format. Jupytext handles the conversion gracefully without expecting the `.py` file to be in JSON format.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "48e812c7-45f4-4adf-9bd3-1dcbc59e9052",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[jupytext] Reading 03_Data-storage-and-access-via-buckets.py in format py\n",
      "[jupytext] Writing 03_Data-storage-and-access-via-buckets-test.ipynb (destination file replaced [use --update to preserve cell outputs and ids])\n"
     ]
    }
   ],
   "source": [
    "# Replace 'your_script.py' with your actual filename\n",
    "!jupytext --to notebook 03_Data-storage-and-access-via-buckets.py --output 03_Data-storage-and-access-via-buckets-test.ipynb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86a6d55-5279-423f-864a-7810dd414def",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os\n",
    "\n",
    "# List all .py files in the directory\n",
    "scripts = [f for f in os.listdir() if f.endswith('.py')]\n",
    "\n",
    "# Convert each .py file to .ipynb using jupytext\n",
    "for script in scripts:\n",
    "    output_file = script.replace('.py', '.ipynb')\n",
    "    subprocess.run([\"jupytext\", \"--to\", \"notebook\", script, \"--output\", output_file])\n",
    "    print(f\"Converted {script} to {output_file}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

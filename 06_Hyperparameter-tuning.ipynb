{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b9c6248-2594-4290-bd53-07fafab3a8cd",
   "metadata": {},
   "source": [
    "Here’s the revised section with detailed information on setting up metrics for hyperparameter tuning jobs:\n",
    "\n",
    "---\n",
    "\n",
    "## Hyperparameter Tuning in SageMaker: Neural Network Example\n",
    "\n",
    "To conduct efficient hyperparameter tuning with neural networks in SageMaker, we’ll leverage SageMaker’s **hyperparameter tuning jobs** while carefully managing parameter ranges and model count. Here’s an overview of the process, with a focus on both efficiency and cost-effectiveness.\n",
    "\n",
    "### Key Steps for Hyperparameter Tuning\n",
    "\n",
    "1. **Define Parameter Ranges**: SageMaker supports both `ContinuousParameter` and `CategoricalParameter` for tuning. \n",
    "   - **`ContinuousParameter`** is ideal when you want to evenly sample numeric values across a range without specifying each exact value. \n",
    "   - **`CategoricalParameter`** allows you to explicitly set the values SageMaker will test, ensuring only specific values are sampled.\n",
    "   \n",
    "2. **Set Up Objective Metrics**: SageMaker relies on objective metrics to assess models and choose the best configuration. Here’s how to set up metrics:\n",
    "   - In the training script, **log the target metric** (e.g., validation accuracy or loss) using `print` statements formatted to match the expected regular expression.\n",
    "   - **Define `metric_definitions`** in both the estimator and tuner configurations. This redundancy can help avoid common errors and ensure the metric is captured correctly.\n",
    "   - Example of logging and regex setup:\n",
    "     ```python\n",
    "     print(f\"validation:accuracy = {val_accuracy:.4f}\", flush=True)\n",
    "     ```\n",
    "   - The `metric_definitions` parameter uses a regular expression to match the logged output, enabling SageMaker to track the desired metric across training jobs.\n",
    "\n",
    "3. **Resource-Conscious Approach**: To control costs, choose efficient instance types and limit the search to impactful parameters, keeping resource consumption in check.\n",
    "\n",
    "### Balancing Tuning Time and Environmental/Monetary Costs\n",
    "\n",
    "Understanding the roles of `instance_count`, `max_jobs`, and `max_parallel_jobs` is key for optimizing tuning time and cost:\n",
    "\n",
    "1. **`instance_count`** (Estimator):\n",
    "   - Specifies the number of instances used per training job. \n",
    "   - Increasing `instance_count` can benefit large datasets or deep networks needing distributed power, but it raises per-job costs. \n",
    "   - **Start with `instance_count=1`** (especially when you're first testing your setup) and increase only if single-instance training is inefficient.\n",
    "\n",
    "2. **`max_jobs`** (HyperparameterTuner):\n",
    "   - Controls the total number of training jobs, representing distinct hyperparameter combinations.\n",
    "   - Begin with a moderate range, such as **10–20 jobs**; expand if further performance improvements justify it.\n",
    "\n",
    "3. **`max_parallel_jobs`** (HyperparameterTuner):\n",
    "   - Sets the number of jobs to run concurrently, impacting overall tuning time but not total cost.\n",
    "   - **Recommended range**: 2–4 for efficiency; increase only if time constraints and budget permit.\n",
    "\n",
    "---\n",
    "\n",
    "### Code Example for SageMaker Hyperparameter Tuning with Neural Networks\n",
    "\n",
    "This setup provides:\n",
    "- **Explicit control** over `epochs` using `CategoricalParameter`, allowing targeted testing of specific values.\n",
    "- **Efficient sampling** for `learning_rate` using `ContinuousParameter`, covering a defined range for a balanced approach.\n",
    "- **Cost control** by setting moderate `max_jobs` and `max_parallel_jobs`.\n",
    "\n",
    "By managing these settings and configuring metrics properly, you can achieve a balanced and efficient approach to hyperparameter tuning for neural networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a9ce3945-6663-4f83-8548-552b5e24b90f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n",
      "No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".......................................................................................................................................................!\n",
      "Hyperparameter tuning job launched.\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "from sagemaker.tuner import HyperparameterTuner, IntegerParameter, ContinuousParameter, CategoricalParameter\n",
    "from sagemaker.pytorch import PyTorch\n",
    "from sagemaker.inputs import TrainingInput\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "# Initialize SageMaker session and role\n",
    "session = sagemaker.Session()\n",
    "role = get_execution_role()\n",
    "bucket = 'titanic-dataset-test'  # replace with your S3 bucket name\n",
    "\n",
    "# Define the PyTorch estimator with entry script and environment details\n",
    "pytorch_estimator = PyTorch(\n",
    "    entry_point=\"test_AWS/train_nn.py\",  # Your script for training\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.m5.large\",\n",
    "    framework_version=\"1.9\",\n",
    "    py_version=\"py38\",\n",
    "    metric_definitions=[{\"Name\": \"validation:accuracy\", \"Regex\": \"validation:accuracy = ([0-9\\\\.]+)\"}],\n",
    "    hyperparameters={\n",
    "        \"train\": \"/opt/ml/input/data/train/train_data.npz\",  # SageMaker will mount this path\n",
    "        \"val\": \"/opt/ml/input/data/val/val_data.npz\",        # SageMaker will mount this path\n",
    "        \"epochs\": 100,\n",
    "        \"learning_rate\": 0.001\n",
    "    },\n",
    "    sagemaker_session=session,\n",
    ")\n",
    "\n",
    "# Hyperparameter tuning ranges\n",
    "hyperparameter_ranges = {\n",
    "    \"epochs\": CategoricalParameter([100, 1000, 10000]),       # Adjust as needed\n",
    "    \"learning_rate\": ContinuousParameter(0.001, 0.1),  # Range for continuous values\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1fb42f4-b124-4837-ba2c-f1d86c76714e",
   "metadata": {},
   "source": [
    "Before running the full search, let's test our setup by setting max_jobs = 1. This will test just one possible hyperparameter configuration. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6399631e-f3cc-4ab0-8f46-ff90ce1d03aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tuner configuration\n",
    "tuner = HyperparameterTuner(\n",
    "    estimator=pytorch_estimator,\n",
    "    metric_definitions=[{\"Name\": \"validation:accuracy\", \"Regex\": \"validation:accuracy = ([0-9\\\\.]+)\"}],\n",
    "    objective_metric_name=\"validation:accuracy\",  # Ensure this matches the metric name exactly\n",
    "    objective_type=\"Maximize\",                   # Specify if maximizing or minimizing the metric\n",
    "    hyperparameter_ranges=hyperparameter_ranges,\n",
    "    max_jobs=1,                # Adjust based on exploration needs (please keep below 30 to be kind to environment)\n",
    "    max_parallel_jobs=1         # Adjust based on available resources and budget\n",
    ")\n",
    "\n",
    "# Define the input paths\n",
    "train_input = TrainingInput(f\"s3://{bucket}/train_data.npz\", content_type=\"application/x-npz\")\n",
    "val_input = TrainingInput(f\"s3://{bucket}/val_data.npz\", content_type=\"application/x-npz\")\n",
    "\n",
    "# Launch the hyperparameter tuning job\n",
    "tuner.fit({\"train\": train_input, \"val\": val_input})\n",
    "print(\"Hyperparameter tuning job launched.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d217a650-5336-4e99-a3d2-938b2fd8ab31",
   "metadata": {},
   "source": [
    "If all goes well, we can scale up the experiment with the below code (20 hyperparameter configurations).\n",
    "\n",
    "After running the below cell, we can check on the progress by visiting the SageMaker Console and finding the \"Training\" tab located on the left panel. Click \"Hyperparmater tuning jobs\" to view running jobs.\n",
    "\n",
    "If you're seeing only \"2/4 training completed\" in the console, it may be because SageMaker initially schedules only a subset of the total jobs to run simultaneously, based on your setting for max_parallel_jobs. Here’s what’s happening:\n",
    "\n",
    "* Initial Jobs: SageMaker starts by running only max_parallel_jobs (2 in this case) as the initial batch. As each job completes, new jobs from the remaining pool are triggered until max_jobs (20) is reached.\n",
    "* Batch Scheduling: The \"2/4\" progress indicates that SageMaker has grouped the jobs into batches and is currently processing the first batch of four jobs (two of which are either in progress or completed). This behavior helps SageMaker optimize resources and allows monitoring to quickly identify high-performing configurations to prioritize in the subsequent batches.\n",
    "* Job Completion: Once the first few jobs complete, SageMaker will continue to launch the remaining jobs up to the maximum of 20, but no more than two at a time.\n",
    "\n",
    "This approach is designed to balance efficient exploration with resource constraints. If you want more jobs to start simultaneously, consider increasing max_parallel_jobs, but keep in mind the potential cost implications of running many jobs concurrently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ac311b-6835-4efb-9166-038064308661",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tuner configuration\n",
    "tuner = HyperparameterTuner(\n",
    "    estimator=pytorch_estimator,\n",
    "    metric_definitions=[{\"Name\": \"validation:accuracy\", \"Regex\": \"validation:accuracy = ([0-9\\\\.]+)\"}],\n",
    "    objective_metric_name=\"validation:accuracy\",  # Ensure this matches the metric name exactly\n",
    "    objective_type=\"Maximize\",                   # Specify if maximizing or minimizing the metric\n",
    "    hyperparameter_ranges=hyperparameter_ranges,\n",
    "    max_jobs=20,                # Adjust based on exploration needs (please keep below 30 to be kind to environment)\n",
    "    max_parallel_jobs=4         # Adjust based on available resources and budget\n",
    ")\n",
    "\n",
    "# Define the input paths\n",
    "train_input = TrainingInput(f\"s3://{bucket}/train_data.npz\", content_type=\"application/x-npz\")\n",
    "val_input = TrainingInput(f\"s3://{bucket}/val_data.npz\", content_type=\"application/x-npz\")\n",
    "\n",
    "# Launch the hyperparameter tuning job\n",
    "tuner.fit({\"train\": train_input, \"val\": val_input})\n",
    "print(\"Hyperparameter tuning job launched.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "637232ff-f4b1-4de9-8057-ca264771b674",
   "metadata": {},
   "source": [
    "### Can/should we run more instances in parallel?\n",
    "Setting max_parallel_jobs to 20 (equal to max_jobs) will indeed launch all 20 jobs in parallel. This approach won’t affect the total cost (since cost is based on the number of total jobs, not how many run concurrently), but it can impact the final results and resource usage pattern due to SageMaker's ability to dynamically select hyperparameter values to test to maximize efficiency and improve model performance. This adaptability is especially useful for neural networks, which often have a large hyperparameter space with complex interactions. Here’s how SageMaker’s approach impacts typical neural network training:\n",
    "\n",
    "### 1. **Adaptive Search Strategies**\n",
    "   - SageMaker offers **Bayesian optimization** for hyperparameter tuning. Instead of purely random sampling, it learns from previous jobs to choose the next set of hyperparameters more likely to improve the objective metric.\n",
    "   - For neural networks, this strategy can help converge on better-performing configurations faster by favoring promising areas of the hyperparameter space and discarding poor ones.\n",
    "\n",
    "### 2. **Effect of `max_parallel_jobs` on Adaptive Tuning**\n",
    "   - When using Bayesian optimization, a lower `max_parallel_jobs` (e.g., 2–4) can allow SageMaker to iteratively adjust and improve its choices. Each batch of jobs informs the subsequent batch, which may yield better results over time.\n",
    "   - Conversely, if all jobs are run in parallel (e.g., `max_parallel_jobs=20`), SageMaker can’t learn and adapt within a single batch, making this setup more like a traditional grid or random search. This approach is still valid, especially for small search spaces, but it doesn’t leverage the full potential of adaptive tuning.\n",
    "\n",
    "### 3. **Practical Impact on Neural Network Training**\n",
    "   - **For simpler models** or smaller parameter ranges, running jobs in parallel with a higher `max_parallel_jobs` works well and quickly completes the search.\n",
    "   - **For more complex neural networks** or large hyperparameter spaces, an adaptive strategy with a smaller `max_parallel_jobs` may yield a better model with fewer total jobs by fine-tuning hyperparameters over multiple iterations.\n",
    "\n",
    "### Summary\n",
    "- **For fast, straightforward tuning**: Set `max_parallel_jobs` closer to `max_jobs` for simultaneous testing.\n",
    "- **For adaptive, refined tuning**: Use a smaller `max_parallel_jobs` (like 2–4) to let SageMaker leverage adaptive tuning for optimal configurations. \n",
    "\n",
    "This balance between exploration and exploitation is particularly impactful in neural network tuning, where training costs can be high and parameters interact in complex ways.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de110b46-ea87-408b-8df2-064e7f9741bd",
   "metadata": {},
   "source": [
    "### Important Details and Best Practices\n",
    "1. **Always Test Before Scaling Up**: Before tunning the full search, make sure to test your code setup with max_jobs set to 1.\n",
    "\n",
    "1. **Parameter Ranges**:\n",
    "   - **Learning Rate**: Cover a wide range (0.0001 to 0.01) as it often has a significant effect.\n",
    "   - **Batch Size**: Typically smaller values are computationally lighter but may require more tuning. Ranging from 16 to 64 here.\n",
    "   - **Hidden Units**: Adjust the number of units per layer within a moderate range (32 to 128) to optimize model complexity without excess.\n",
    "\n",
    "2. **Objective Metric**: Choose `validation_loss` to minimize overfitting; it’s parsed from log outputs by the specified `Regex`.\n",
    "\n",
    "3. **Instance Count for Tuning**:\n",
    "   - **Parallel Jobs**: Run up to 5 jobs in parallel to utilize multiple instances and speed up the search.\n",
    "   - **Instance Type**: `ml.m5.large` balances cost and performance for this job, though `ml.m5.xlarge` is a possible upgrade if needed.\n",
    "\n",
    "4. **Environmental Considerations**:\n",
    "   - By limiting hyperparameter jobs to 10-20, we reduce carbon footprint and resource usage. Only critical parameters are tuned, and a limited range helps avoid unnecessary jobs.\n",
    "   - Encourage reusing efficient hyperparameters in similar tasks, reducing the need for repeated tuning.\n",
    "\n",
    "5. **Monitoring and Results**:\n",
    "   - SageMaker’s `tuner` job will report validation loss for each configuration, and you can select the optimal one based on these results.\n",
    "   - Consider logging model performances and job configurations to guide future jobs, reducing redundancy.\n",
    "\n",
    "This setup demonstrates a responsible yet effective approach to hyperparameter tuning with distributed SageMaker instances, allowing for both environmental and cost efficiency without sacrificing performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cbfa1cf-7f03-4e75-b97c-fe217209dd35",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 1. Retrieve the Best Training Job from the Tuning Job\n",
    "First, let’s retrieve details about the best model from the tuning job. This will include the best hyperparameters and access to the model artifacts.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e17f5064-3a11-46ea-bc22-7824053e0180",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best training job name: pytorch-training-241029-2307-015-b999e972\n",
      "Best hyperparameters: {'_tuning_objective_metric': 'validation:accuracy', 'epochs': '\"100\"', 'learning_rate': '0.002292278623021597', 'sagemaker_container_log_level': '20', 'sagemaker_estimator_class_name': '\"PyTorch\"', 'sagemaker_estimator_module': '\"sagemaker.pytorch.estimator\"', 'sagemaker_job_name': '\"pytorch-training-2024-10-29-23-07-03-095\"', 'sagemaker_program': '\"train_nn.py\"', 'sagemaker_region': '\"us-east-1\"', 'sagemaker_submit_directory': '\"s3://sagemaker-us-east-1-183295408236/pytorch-training-2024-10-29-23-07-03-095/source/sourcedir.tar.gz\"', 'train': '\"/opt/ml/input/data/train/train_data.npz\"', 'val': '\"/opt/ml/input/data/val/val_data.npz\"'}\n"
     ]
    }
   ],
   "source": [
    "# Get the best training job from the completed tuning job\n",
    "best_training_job = tuner.best_training_job()\n",
    "print(\"Best training job name:\", best_training_job)\n",
    "\n",
    "# Retrieve best hyperparameters\n",
    "best_job_desc = session.sagemaker_client.describe_training_job(TrainingJobName=best_training_job)\n",
    "best_hyperparameters = best_job_desc[\"HyperParameters\"]\n",
    "print(\"Best hyperparameters:\", best_hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3784f1a5-ffe0-41f2-a8f3-2fa54df64417",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training time across all jobs: 0.12 hours\n",
      "Estimated total billing time across all jobs: 0.12 hours\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "\n",
    "# # Initialize SageMaker client\n",
    "sagemaker_client = boto3.client(\"sagemaker\")\n",
    "\n",
    "# Retrieve tuning job details\n",
    "tuning_job_name = tuner.latest_tuning_job.name  # Replace with your tuning job name if needed\n",
    "tuning_job_desc = sagemaker_client.describe_hyper_parameter_tuning_job(HyperParameterTuningJobName=tuning_job_name)\n",
    "\n",
    "# Retrieve all training jobs for the tuning job\n",
    "training_jobs = sagemaker_client.list_training_jobs_for_hyper_parameter_tuning_job(\n",
    "    HyperParameterTuningJobName=tuning_job_name, StatusEquals='Completed'\n",
    ")[\"TrainingJobSummaries\"]\n",
    "\n",
    "# Calculate total training and billing time\n",
    "total_training_time = 0\n",
    "total_billing_time = 0\n",
    "\n",
    "for job in training_jobs:\n",
    "    job_name = job[\"TrainingJobName\"]\n",
    "    job_desc = sagemaker_client.describe_training_job(TrainingJobName=job_name)\n",
    "    \n",
    "    # Calculate training time (in seconds)\n",
    "    training_time = job_desc[\"TrainingEndTime\"] - job_desc[\"TrainingStartTime\"]\n",
    "    total_training_time += training_time.total_seconds()\n",
    "    \n",
    "    # Calculate billed time (in seconds, rounded up to the nearest second)\n",
    "    billed_time = job_desc[\"ResourceConfig\"][\"InstanceCount\"] * training_time.total_seconds()\n",
    "    total_billing_time += billed_time\n",
    "\n",
    "# Print total compute and billing time\n",
    "print(f\"Total training time across all jobs: {total_training_time / 3600:.2f} hours\")\n",
    "print(f\"Estimated total billing time across all jobs: {total_billing_time / 3600:.2f} hours\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a575ce8-deca-4c42-ac9d-bf7442cd87bd",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### 2. Deploy the Best Model as an Endpoint (Optional)\n",
    "If you want to deploy the best model as a SageMaker endpoint for real-time inference, you can use the following code:\n",
    "\n",
    "```python\n",
    "# Deploy the best model to an endpoint\n",
    "best_predictor = tuner.deploy(\n",
    "    initial_instance_count=1, \n",
    "    instance_type=\"ml.m5.large\"\n",
    ")\n",
    "\n",
    "# Example inference call\n",
    "import numpy as np\n",
    "test_data = np.array([[...]])  # Replace with sample test data\n",
    "predictions = best_predictor.predict(test_data)\n",
    "print(\"Predictions:\", predictions)\n",
    "```\n",
    "\n",
    "### 3. Download the Best Model Artifacts for Local Evaluation\n",
    "If you want to use the best model locally or load it for further analysis, you can download the model artifacts from S3:\n",
    "\n",
    "```python\n",
    "import boto3\n",
    "\n",
    "# Specify where to save the model locally\n",
    "local_model_path = \"best_model.tar.gz\"\n",
    "\n",
    "# Get the model artifacts S3 path\n",
    "model_s3_path = best_job_desc[\"ModelArtifacts\"][\"S3ModelArtifacts\"]\n",
    "print(\"Model artifact S3 path:\", model_s3_path)\n",
    "\n",
    "# Download the model\n",
    "s3 = boto3.client(\"s3\")\n",
    "s3.download_file(\n",
    "    Bucket=model_s3_path.split('/')[2],\n",
    "    Key='/'.join(model_s3_path.split('/')[3:]),\n",
    "    Filename=local_model_path\n",
    ")\n",
    "print(\"Best model downloaded to:\", local_model_path)\n",
    "```\n",
    "\n",
    "### 4. Unpack and Load the Model Locally (for PyTorch example)\n",
    "Assuming this is a PyTorch model, you can unpack and load it:\n",
    "\n",
    "```python\n",
    "import torch\n",
    "\n",
    "# Extract and load the model (assuming the model is saved as `model.pth` in the archive)\n",
    "import tarfile\n",
    "\n",
    "with tarfile.open(local_model_path, \"r:gz\") as tar:\n",
    "    tar.extractall(\"model_dir\")\n",
    "\n",
    "# Load the model\n",
    "model = TitanicNet()  # Initialize your model class\n",
    "model.load_state_dict(torch.load(\"model_dir/nn_model.pth\"))\n",
    "model.eval()  # Set to evaluation mode\n",
    "\n",
    "# Now `model` is ready for inference or evaluation on test data\n",
    "```\n",
    "\n",
    "### 5. Evaluate the Best Model on a Test Set\n",
    "Use your test dataset for final evaluation, as follows:\n",
    "\n",
    "```python\n",
    "# Assuming you have test data in numpy format\n",
    "test_data = np.load(\"test_data.npz\")\n",
    "X_test = torch.tensor(test_data['X_test'], dtype=torch.float32)\n",
    "y_test = torch.tensor(test_data['y_test'], dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "# Inference and evaluation\n",
    "with torch.no_grad():\n",
    "    predictions = model(X_test)\n",
    "    predictions = predictions.round()  # Round for binary classification\n",
    "    accuracy = (predictions == y_test).float().mean().item()\n",
    "    print(f\"Test Set Accuracy: {accuracy:.4f}\")\n",
    "```\n",
    "\n",
    "These steps provide a comprehensive approach to accessing, deploying, and evaluating the best model from your tuning job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d7b988b-a44c-4761-a546-0f7df2cdc524",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
